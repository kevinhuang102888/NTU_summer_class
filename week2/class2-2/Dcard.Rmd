---
title: "Dcard成大版分析"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# 簡介


Dcard為目前台灣大學生常用的社群APP之一，有許多各式各樣的論壇版，其中成功大學又常被稱為「廢文大學」，喜歡PO一些無聊、沒意義的文章，又常戰系、戰學校，但事情真的是如此嗎?

這次的資料分析想要透過研究Dcard的成大版，從2019/07/19的最後一篇文章，回推取100篇Dcard文章來分析，從這些文章可以深入研究，討論成大版最常討論的詞彙或者什麼人比較常PO文等等問題，進而回復「成大是否為廢文大學?」。

===

1.先將需要的library載入

```{r warning=FALSE}
# load the library
#爬蟲使用
library(httr)
library(jsonlite)
#文字整理
library(tm)
#斷詞
library(jiebaRD)
library(jiebaR)
#資料切割、篩選
library(dplyr)
#畫圖
library(ggplot2)
#文字雲
library(wordcloud)
```

2.預設字串不要轉成factor、讀檔用UTF-8

```{r}
options(stringsAsFactors = FALSE)
options(encoding = "UTF-8")

```

3.自訂三個function：

(1)用於取得每篇文章的內文
(2)用於取得每篇文章的留言
(3)用於中文斷詞,且每個詞數至少需要大於1

```{r}
#get the Dcard post(input: url & Dcard id )
getcontent<-function(dcardurl,id){
  mainurl<- paste0(dcardurl,id,collapse="")
  resdata<- jsonlite::fromJSON(httr::content(GET(mainurl),"text",encoding = "UTF-8"))
  toString(resdata$content)
}
#get all the comment in each post(input: url & Dcard id )
getcomment<-function(dcardurl,id){
  mainurl<- paste0(dcardurl,id,'/comments?limit=50',collapse="")
  json<-httr::content(GET(mainurl), "text",encoding = "UTF-8")
  resdata<- jsonlite::fromJSON(json)
  toString(resdata$content)
}
# get the chinese word
myFUN<- function(str,term) {
  str = gsub("[A-Za-z0-9]", "", str)
  seg = cutter[str]
  seg = seg[names(seg)==term]
  id = which(nchar(seg) > 1)
  result = seg[id]
}
```

4.爬蟲100文章的基本資料，例如：用戶id、學校名稱、科系、讚數、留言數等等(除了文章內容以及每篇文章的留言內容)

```{r}
dcardurl <- 'https://www.dcard.tw/_api/forums/ncku/'
mainurl <- paste0(dcardurl,'posts?popular=false&limit=100&before=231705029')
resdata<- fromJSON(httr::content(GET(mainurl), 'text'))
```

5.利用function求出內文跟留言內容，並併入resdata裡

```{r}
content<-unlist(lapply(resdata$id,getcontent,dcardurl='https://www.dcard.tw/_api/posts/'))
comment<-unlist(lapply(resdata$id,getcomment,dcardurl='https://www.dcard.tw/_api/posts/'))

Dcard<-data.frame(resdata$id,resdata$title,resdata$createdAt,
                  resdata$updatedAt,resdata$department,
                  resdata$commentCount,resdata$likeCount,
                  resdata$gender,content,comment)
head(Dcard)
```

6.斷詞設定器，並取得文字的詞性，和加入新詞彙「成大」。

**註**write = "NOFILE"用於防止讀檔的問題

```{r}
#set the cutter
cutter <- worker('tag',write = "NOFILE")
new_user_word(cutter,'成大','n')
new_user_word(cutter,'韓國瑜','n')
new_user_word(cutter,'韓粉','n')
new_user_word(cutter,'蔡英文','n')
new_user_word(cutter,'甲甲','n')
new_user_word(cutter,'民進黨','n')
```

7.套用function，將所有內文斷詞，並做次數累積

```{r}
#cut the post
txt1<-unlist(lapply(Dcard$content[1:100],myFUN,'n'))
st1<-freq(txt1)
st1<-st1[order(st1$freq,decreasing = TRUE),]
```

8.文字雲

內文的文字雲

```{r}
wordcloud(words=st1$char,freq=st1$freq,scale = c(3,0.1), # 給定文字尺寸的區間（向量）
          random.order = F,# 關閉文字隨機顯示 按順序
          ordered.colors = F,#關閉配色順序
          rot.per = F,#關閉文字轉角度
          min.freq = 3,# 定義最小freq數字 
          colors = brewer.pal(8,"Dark2")
)
```


9.結論

從文字雲可以看出，在7/15-7/19這幾天中，主要都討論「選課、轉系資訊有關」，像是成績、學分、科系、書卷、條件或是機會，都是跟轉系有關，其中可以看出「法律系」、「電機系」以及「醫學系」討論熱烈，另外，還可以發現有一個小主題，談論到女生的部分蠻多的，像是女生、條件、高富帥、婊子或女人，看來成大學生在Dcard上蠻常討論女生的，不管是女生喜歡男生的樣子，或是形容女生，看來真的是肥宅學校XD(有點小小仇女)